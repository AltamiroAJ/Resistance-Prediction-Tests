{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from sklearn.model_selection import train_test_split  \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from keras_visualizer import visualizer \n",
    "import datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readInputParams(file_name):\n",
    "    df_params = pd.read_csv(file_name, index_col=False)\n",
    "\n",
    "    df_params = df_params.rename(columns={\n",
    "        'modelo': 'name',\n",
    "        'entrada': 'input_columns',\n",
    "        'velocidades': 'velocity_columns',\n",
    "        'camadas internas': 'num_hidden_layers',\n",
    "        'num neuronios internos': 'num_neurons_per_hidden_layer',\n",
    "        'funcao de ativacao': 'activation_func'\n",
    "        })\n",
    "    \n",
    "    df_params['input_columns'] = df_params['input_columns'].apply(lambda value: [x.strip() for x in value.split(',')])\n",
    "    df_params['velocity_columns'] = df_params['velocity_columns'].apply(lambda value: [x.strip() for x in value.split(',')])\n",
    "\n",
    "    return df_params.to_dict('records') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparaDataset(params, df_original):\n",
    "     \n",
    "       df = df_original[params['input_columns']]\n",
    "       \n",
    "       duplicated_df = pd.concat([df] * len(params['velocity_columns']), ignore_index=True)\n",
    "\n",
    "       velo_df = df_original[params['velocity_columns']]\n",
    "\n",
    "       velo_df = velo_df.melt(var_name='Velocity', value_name='Resistance')\n",
    "      \n",
    "       full_df = duplicated_df.join(velo_df, lsuffix='a', rsuffix='b')\n",
    "\n",
    "       X = np.asarray(full_df.iloc[:, 0:len(params['input_columns']) + 1].values).astype('float32')\n",
    "       y = np.asarray(full_df['Resistance'].values).astype('float32')  \n",
    "\n",
    "       return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def splitDataset(X, y, test_size=0.15, val_size=0.15, random_state=None):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_size, random_state=random_state)\n",
    "\n",
    "    X_train = np.asarray(X_train).astype('float32')\n",
    "    y_train = np.asarray(y_train).astype('float32')\n",
    "    X_val = np.asarray(X_val).astype('float32')\n",
    "    y_val = np.asarray(y_val).astype('float32')\n",
    "    X_test = np.asarray(X_test).astype('float32')\n",
    "    y_test = np.asarray(y_test).astype('float32')\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildTopology(params): \n",
    "    topology = []\n",
    "\n",
    "    input_layer = keras.layers.Input(len(params['input_columns']) + 1, name='input')\n",
    "    topology.append(input_layer)\n",
    "\n",
    "    hidden_layers = []\n",
    "\n",
    "    num_neurons = params['num_neurons_per_hidden_layer']\n",
    "\n",
    "    for i in range(params['num_hidden_layers']):\n",
    "        inner_layer = keras.layers.Dense(num_neurons, activation=tf.nn.relu, name='inner' + str(i))\n",
    "        hidden_layers.append(inner_layer)\n",
    "\n",
    "    topology += hidden_layers\n",
    "\n",
    "    output_layer = keras.layers.Dense(1, name='output')\n",
    "    topology.append(output_layer)\n",
    "\n",
    "    return topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(params, train_set, val_set, number_epochs):\n",
    "    topology = buildTopology(params)\n",
    "\n",
    "    model = keras.Sequential(topology)\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mean_absolute_percentage_error'])\n",
    "\n",
    "    history = model.fit(*train_set, epochs=number_epochs, batch_size=15, validation_data=val_set)\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perGenerationLoss(history, params, number_epochs): \n",
    "    loss_train = history.history['loss']\n",
    "    loss_val = history.history['val_loss']\n",
    "    epochs = range(1, number_epochs + 1)\n",
    "\n",
    "    df = pd.DataFrame(data = {\n",
    "        'epoch': epochs,\n",
    "        'loss_train': loss_train,\n",
    "        'loss_val': loss_val\n",
    "    })\n",
    "\n",
    "    df.to_csv(sub_folder_name + '/loss_per_generation.csv', index=False)\n",
    "\n",
    "    plt.plot(epochs, loss_train, 'g', label='Conjunto de treinamento')\n",
    "    plt.plot(epochs, loss_val, 'b', label='Conjunto de validação')\n",
    "    plt.title('Erro quadrático médio por conjunto por geração')\n",
    "    plt.xlabel('Geração')\n",
    "    plt.ylabel('Erro quadrático médio')\n",
    "    plt.legend()\n",
    "    plt.savefig(sub_folder_name + '/loss_per_generation.png')\n",
    "    plt.show()\n",
    "\n",
    "def generateReports(model, history, full_dataset, splitted_dataset, params, number_epochs):\n",
    "    perGenerationLoss(history, params, number_epochs)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_sets = readInputParams('params.csv')\n",
    "\n",
    "df_original = pd.read_csv('Banco de Dados - Completo.csv')\n",
    "\n",
    "test_vessel_indexes = np.array(random.sample(range(0, 53), 4)) - 1\n",
    "\n",
    "print('Selected vessels for testing: ', test_vessel_indexes)\n",
    "\n",
    "df_train = df_original[~df_original.index.isin(test_vessel_indexes)]\n",
    "\n",
    "df_test = df_original[df_original.index.isin(test_vessel_indexes)]\n",
    "\n",
    "number_epochs = 100\n",
    "\n",
    "num_trials_per_model = 10\n",
    "\n",
    "parent_folder_name = 'results/' + datetime.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n",
    "\n",
    "for params in param_sets:\n",
    "    \n",
    "    dataset_test = preparaDataset(params, df_test)\n",
    "    dataset = preparaDataset(params, df_train)\n",
    "    X_train, y_train, X_val, y_val = splitDataset(*dataset)\n",
    "\n",
    "    best_model = None\n",
    "    best_global_loss = 999999\n",
    "\n",
    "    for i in range(num_trials_per_model):\n",
    "        model, history = trainModel(params, (X_train, y_train), (X_val, y_val), number_epochs)\n",
    "\n",
    "        global_loss = model.evaluate(*dataset, return_dict=True)['loss']\n",
    "\n",
    "        if global_loss < best_global_loss:\n",
    "            best_global_loss = global_loss\n",
    "            best_model = model\n",
    "\n",
    "    sub_folder_name = parent_folder_name + '/' + params['name']\n",
    "\n",
    "    best_model.save(sub_folder_name + '/model.keras')\n",
    "    \n",
    "    generateReports(best_model, history, dataset_test, (X_train, y_train, X_val, y_val, *dataset_test), params, number_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('rede neural - VRP': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ed876df83bcec954cb861f45e23a5a0ecfd0cf701e0b7d9555ac43b30432f01"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
